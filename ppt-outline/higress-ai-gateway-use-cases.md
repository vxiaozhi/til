# Higress AI 网关使用场景 PPT 大纲

## 第一部分：AI 网关概述

### 1. Higress AI 网关定位
- **什么是 AI 网关**
  - AI Gateway = AI Native API Gateway
  - AI 是一等公民的 API 网关
  - 为 AI 时代专门设计的网关能力

- **为什么需要 AI 网关**
  - 多模型厂商管理复杂
  - API 调用成本控制困难
  - 缺乏统一的可观测性
  - 数据安全和隐私保护需求
  - 需要增强 AI 能力（缓存、搜索等）

- **Higress 在 AI 领域的应用**
  - 支撑通义千问 APP
  - 服务百炼大模型 API
  - 支持机器学习 PAI 平台
  - 服务零一万物等头部 AIGC 企业
  - 集成于 FastGPT 等 AI 产品

### 2. AI 网关核心价值
- **统一多模型接入**
  - 兼容 OpenAI 和 Claude 协议
  - 支持国内外 30+ 主流 LLM 厂商
  - 自动协议转换
  - 模型映射和路由

- **成本优化**
  - Token 级别的流控
  - 智能缓存降低成本
  - Quota 配额管理
  - 多模型负载均衡

- **安全合规**
  - 数据脱敏
  - 敏感词过滤
  - API 密钥管理
  - 访问控制

- **能力增强**
  - AI 缓存加速
  - 搜索增强
  - Agent 编排
  - 多轮对话

## 第二部分：AI 服务提供商管理（API Provider）

### 3. AI 代理 - 统一多模型接入
- **支持的 AI 服务商（30+）**
  - **国际厂商**：OpenAI、Azure OpenAI、Anthropic Claude、Google Gemini、AWS Bedrock
  - **国内厂商**：通义千问、文心一言、智谱 AI、月之暗面、百川智能、零一万物
  - **开源模型**：Ollama、Hugging Face
  - **聚合平台**：OpenRouter、Fireworks AI、Together-AI

- **自动协议兼容**
  - OpenAI 协议：`/v1/chat/completions`
  - Claude 协议：`/v1/messages`
  - 向量化协议：`/v1/embeddings`
  - 智能协议转换（供应商不支持时自动转换）
  - 零配置自动检测

- **模型映射和管理**
  - 前缀匹配：`gpt-3-*` 匹配所有 gpt-3 模型
  - 正则匹配：`~gpt(.*)` 支持正则表达式
  - 通配符兜底：`*` 设置默认模型
  - 动态模型切换

- **高级特性**
  - 多 Token 负载均衡
  - Token Failover 机制
  - 健康检查和自动切换
  - 重试策略配置
  - 自定义参数注入（max_tokens、temperature 等）

**适用场景**：
- 多云/多厂商 LLM 服务管理
- 模型统一调用入口
- 降低模型切换成本
- 提高服务可用性

### 4. AI 缓存 - 降低成本和延迟
- **两种缓存模式**
  - **语义缓存**：基于向量数据库的相似问题匹配
  - **精确缓存**：基于 Redis 的字符串精确匹配

- **支持的向量数据库**
  - DashVector（阿里云）
  - Elasticsearch
  - Milvus
  - Pinecone
  - Qdrant
  - Weaviate
  - Chroma

- **支持的 Embedding 服务**
  - OpenAI
  - 通义千问（DashScope）
  - 讯飞星火
  - Textln
  - Hugging Face
  - Cohere

- **灵活的缓存策略**
  - 可配置缓存键提取规则（GJSON Path）
  - 支持流式和非流式响应
  - 可设置缓存过期时间
  - 支持缓存 Key 前缀管理
  - 通过请求头控制缓存跳过

- **缓存效果**
  - 命中缓存后延迟降至毫秒级
  - Token 消耗为 0
  - 显著降低 API 调用成本

**适用场景**：
- 高频重复问题场景（客服、FAQ）
- 降低大模型调用成本
- 提升响应速度
- 知识库问答系统

### 5. AI 提示词装饰器 - Prompt 管理
- **功能说明**
  - 在原始请求基础上添加系统提示词
  - 支持在消息开头或结尾插入
  - 不影响用户原始对话内容

- **应用价值**
  - 统一设置角色定位
  - 注入业务规则约束
  - 添加输出格式要求
  - 实现 Prompt 模板管理

**适用场景**：
- 企业知识助手
- 客服机器人
- 专业领域对话系统
- Prompt 工程优化

### 6. AI 安全防护 - 内容安全
- **多层防护机制**
  - 敏感词拦截
  - 内容审核
  - 注入攻击防护
  - 越狱提示词识别

- **灵活的策略配置**
  - 预置安全规则库
  - 自定义黑白名单
  - 可配置拦截响应

**适用场景**：
- 企业合规要求
- 内容安全审核
- 防止恶意利用
- 青少年模式

## 第三部分：AI 消费端管理（API Consumer）

### 7. AI Token 限流 - 精细化流控
- **两种限流模式**
  - **全局限流**：基于规则名称的全局 Token 限制
  - **Key 级动态限流**：根据用户身份分组限流

- **限流维度**
  - 按请求参数（apikey）
  - 按请求头（x-ca-key）
  - 按 Consumer 名称
  - 按 Cookie 键值
  - 按客户端 IP
  - 支持正则匹配和通配符

- **灵活的时间粒度**
  - 每秒 Token 数（token_per_second）
  - 每分钟 Token 数（token_per_minute）
  - 每小时 Token 数（token_per_hour）
  - 每天 Token 数（token_per_day）

- **基于 Redis 的分布式限流**
  - 精确的 Token 计数
  - 支持多网关实例共享
  - 实时生效

**适用场景**：
- SaaS 平台按量计费
- 防止 API 滥用
- 多租户资源隔离
- 成本控制和预算管理

### 8. AI 配额管理 - Quota 动态管理
- **Quota 管理能力**
  - 查询 Quota 余额
  - 刷新 Quota 配额
  - 增减 Quota 数量
  - 基于 Consumer 的精细化管理

- **管理 API**
  - **刷新 Quota**：`POST /quota/refresh`
  - **查询 Quota**：`GET /quota?consumer=xxx`
  - **增减 Quota**：`POST /quota/delta`

- **权限控制**
  - 基于 admin_consumer 的管理员认证
  - 安全的 API 访问控制
  - 灵活的路径前缀配置

**适用场景**：
- 企业客户 Quota 分配
- SaaS 订阅服务管理
- 灵活的充值和扣费
- 配额预警和控制

### 9. AI 数据脱敏 - 隐私保护
- **三种处理范围**
  - OpenAI 协议：对话内容脱敏
  - JSONPath：指定字段脱敏
  - Raw Body：全文脱敏

- **敏感词拦截**
  - 系统内置敏感词库
  - 自定义敏感词列表
  - 请求/响应双向拦截
  - 可配置拦截响应

- **敏感词替换**
  - 手机号脱敏：13800138000 → ****
  - 邮箱脱敏：admin@gmail.com → ****@gmail.com
  - IP 脱敏：192.168.0.1 → ***.***.***.***.***
  - 身份证脱敏：110000000000000000 → ****
  - API Key Hash：sk-12345 → hash 值

- **数据还原机制**
  - 支持部分脱敏数据还原
  - Hash 值自动映射回原值
  - 确保数据不出域

**适用场景**：
- 数据合规要求
- 隐私保护
- 敏感信息防泄露
- 企业知识产权保护

## 第四部分：AI 可观测性（API Observability）

### 10. AI 统计 - 全方位监控
- **多维度 Metrics**
  - **Input Token 统计**：累计输入 Token 数
  - **Output Token 统计**：累计输出 Token 数
  - **首 Token 延迟**：流式请求首个 Token 的响应时间
  - **总响应时间**：完整请求的耗时统计
  - **请求计数**：流式和非流式请求次数

- **四个观测维度**
  - **网关维度**：整体流量监控
  - **路由维度**：不同路由的使用情况
  - **服务维度**：后端 LLM 服务性能
  - **模型维度**：不同模型的调用统计

- **计算公式示例**
  - 平均首 Token 延迟 = 首 Token 延迟累计 / 流式请求次数
  - 平均响应时间 = 总耗时 / 总请求次数
  - Token 消耗率 = Token 消耗总数 / 时间窗口

- **日志增强**
  - 记录 model、input_token、output_token
  - 记录延迟指标（llm_first_token_duration、llm_service_duration）
  - 支持自定义字段提取（GJSON Path）
  - 可配置问题和回答内容记录

- **链路追踪集成**
  - 支持添加自定义 Span Attributes
  - 可追踪完整的 AI 调用链路
  - 便于问题排查和性能优化

- **自定义可观测字段**
  - 从请求头提取：Consumer 信息
  - 从请求 Body 提取：用户问题内容
  - 从响应 Body 提取：AI 回答内容
  - 从流式响应提取：拼接完整回答
  - 支持固定值注入

**适用场景**：
- API 调用成本分析
- 性能监控和优化
- 用户行为分析
- SLA 保障
- 问题诊断和追踪

## 第五部分：AI 开发增强（API Development）

### 11. AI Agent - 工具调用编排
- **Agent 能力**
  - 基于 ReAct 模式的 Agent 实现
  - 支持多轮对话和工具调用
  - 支持流式和非流式模式
  - 可配置最大迭代次数

- **工具集成**
  - **GET 类型 API**：高德地图、心知天气
  - **POST 类型 API**：DeepL 翻译
  - OpenAPI 3.1 规范描述
  - 支持 Header/Query 认证

- **工作流程**
  1. 用户提问
  2. LLM 理解需求并选择工具
  3. 执行工具调用获取数据
  4. LLM 整合结果生成回答
  5. 支持多轮工具调用

- **配置灵活性**
  - 可自定义 Prompt 模板
  - 支持中英文模板
  - 配置超时和重试
  - Token 限制控制

**适用场景**：
- 智能助手
- 旅游规划
- 信息查询
- 任务自动化
- 复杂业务流程编排

### 12. AI 搜索增强 - RAG 能力
- **支持的搜索引擎**
  - **通用搜索**：Google、Bing
  - **学术搜索**：Arxiv（论文检索）
  - **私有知识库**：Elasticsearch
  - **国内搜索**：夸克

- **搜索重写（强烈推荐）**
  - 使用 LLM 优化搜索查询
  - 自动识别是否需要搜索
  - 转换自然语言为搜索关键词
  - Arxiv：自动识别论文类别
  - Elasticsearch：拆分精准关键词
  - 支持生成多个搜索查询（1-5 个）

- **智能结果整合**
  - 自动将搜索结果注入 Prompt
  - 可配置引用来源展示
  - 支持自定义引用格式
  - 引用位置可配（开头/结尾）

- **高级特性**
  - 多搜索引擎并发查询
  - 结果分页和偏移
  - 超时控制
  - 按需启用（通过 web_search_options）
  - 动态调整搜索深度（low/medium/high）

- **Elasticsearch 私有知识库**
  - 混合搜索（BM25 + 向量）
  - Reciprocal Rank Fusion (RRF)
  - 内置 Embedding 模型
  - 支持第三方 Embedding

**适用场景**：
- 实时信息查询（新闻、天气）
- 学术论文检索
- 企业知识库问答
- RAG（检索增强生成）
- 提高回答准确性和时效性

### 13. AI JSON 响应 - 结构化输出
- **功能说明**
  - 强制 AI 按照 JSON Schema 返回
  - 确保输出格式可预测
  - 便于下游系统解析

- **应用价值**
  - 结构化数据提取
  - API 集成对接
  - 数据验证和校验

**适用场景**：
- 信息抽取
- 表单填充
- 数据标准化
- API 响应格式化

### 14. AI Prompt 模板 - 提示词工程
- **模板管理**
  - 预定义 Prompt 模板
  - 变量替换机制
  - 版本控制

- **最佳实践**
  - 角色设定
  - 任务描述
  - 输出约束
  - 示例展示（Few-shot）

**适用场景**：
- Prompt 工程优化
- 企业知识库
- 专业领域应用
- A/B 测试

## 第六部分：其他 AI 能力

### 15. AI 对话历史管理
- **功能说明**
  - 自动管理多轮对话上下文
  - 支持会话状态保持
  - 基于 Redis 的分布式存储

- **配置选项**
  - 最大历史轮数
  - 会话过期时间
  - 上下文窗口控制

**适用场景**：
- 客服对话
- 智能助手
- 连续问答
- 上下文相关任务

### 16. AI 意图识别
- **功能说明**
  - 识别用户意图并路由
  - 支持多意图分类
  - 可配置意图规则

- **应用价值**
  - 智能路由到不同模型
  - 任务分类和分发
  - 优化成本和性能

**适用场景**：
- 多任务处理
- 智能客服分流
- 模型选择优化

### 17. AI RAG - 知识增强
- **功能说明**
  - 检索增强生成
  - 向量数据库集成
  - 知识库查询

- **支持的向量库**
  - Pinecone
  - Milvus
  - Qdrant
  - Elasticsearch

**适用场景**：
- 企业知识库
  - 文档问答
- 专业知识查询
- 降低幻觉

### 18. AI 请求/响应转换
- **功能说明**
  - 请求格式转换
  - 响应格式适配
  - 协议兼容处理

- **应用场景**
  - 遗留系统集成
  - 多协议支持
  - 定制化需求

## 第七部分：典型应用场景

### 19. 场景一：多模型管理平台
**业务需求**：
- 接入多个 LLM 服务商
- 根据成本和性能选择模型
- 统一的 API 接口

**解决方案**：
```
用户请求 
  → Higress AI Proxy（协议转换 + 模型路由）
  → 多个 LLM 服务商（OpenAI/通义千问/文心等）
  → 统一返回格式
```

**使用的插件**：
- ai-proxy：多模型接入
- ai-statistics：监控不同模型的使用情况
- ai-token-ratelimit：控制各模型调用频率

**收益**：
- 降低 50% 的模型切换成本
- 统一接口降低开发复杂度
- 灵活的模型选择策略

### 20. 场景二：企业智能客服系统
**业务需求**：
- 高频重复问题
- 降低 API 调用成本
- 数据安全合规

**解决方案**：
```
用户问题 
  → 数据脱敏（ai-data-masking）
  → 缓存检查（ai-cache）
  → 命中：直接返回 / 未命中：调用 LLM
  → 结果脱敏还原
  → 返回用户
```

**使用的插件**：
- ai-cache：语义缓存，降低 80% 的重复请求
- ai-data-masking：敏感信息脱敏
- ai-statistics：监控缓存命中率

**收益**：
- 缓存命中率 80%，成本降低 75%
- 响应延迟从 2s 降至 100ms
- 100% 敏感信息保护

### 21. 场景三：SaaS 平台 API 服务
**业务需求**：
- 多租户隔离
- 按量计费
- API 滥用防护

**解决方案**：
```
API 请求（携带 apikey）
  → 认证鉴权（key-auth）
  → Token 限流检查（ai-token-ratelimit）
  → Quota 扣减（ai-quota）
  → 调用 LLM
  → 统计和计费（ai-statistics）
```

**使用的插件**：
- key-auth：API Key 认证
- ai-token-ratelimit：按用户级别限流
- ai-quota：配额管理和扣费
- ai-statistics：计费统计

**收益**：
- 精确的 Token 级别计费
- 防止 API 滥用和恶意调用
- 灵活的配额和充值管理

### 22. 场景四：学术论文检索助手
**业务需求**：
- 实时论文检索
- 专业领域问答
- 准确性要求高

**解决方案**：
```
用户问题
  → 搜索重写（ai-search + LLM）
  → Arxiv 搜索（自动识别类别）
  → 结果整合到 Prompt
  → LLM 生成回答（带引用）
```

**使用的插件**：
- ai-search：Arxiv 搜索集成
- searchRewrite：LLM 优化搜索关键词
- ai-proxy：调用 LLM 生成回答

**收益**：
- 自动识别论文领域和关键词
- 回答准确性提升 60%
- 提供可验证的引用来源

### 23. 场景五：企业知识库问答
**业务需求**：
- 私有知识库检索
- 准确回答企业内部问题
- 数据不出域

**解决方案**：
```
用户问题
  → 搜索重写（拆分关键词）
  → Elasticsearch 混合搜索（BM25 + 向量）
  → 知识片段整合到 Prompt
  → 私有化部署的 LLM
  → 带引用的回答
```

**使用的插件**：
- ai-search：Elasticsearch 集成
- searchRewrite：优化搜索查询
- ai-proxy：调用私有 LLM
- ai-data-masking：数据保护

**收益**：
- 知识检索准确率 85%+
- 数据 100% 本地化
- 降低幻觉，提供可验证答案

### 24. 场景六：智能旅游助手
**业务需求**：
- 多工具调用（地图、天气、翻译）
- 多轮对话
- 流式响应

**解决方案**：
```
用户："我想在北京找个咖啡厅"
  → AI Agent 分析
  → 调用高德地图 API
  → 调用天气 API
  → LLM 整合信息
  → 流式返回推荐
```

**使用的插件**：
- ai-agent：工具编排和调用
- ai-history：对话历史管理
- ai-statistics：监控工具调用情况

**收益**：
- 自动化工具选择和调用
- 智能整合多源信息
- 流畅的对话体验

## 第八部分：部署和最佳实践

### 25. 部署架构建议
- **小规模场景**
  - Docker Compose 单机部署
  - Redis 单实例
  - 适合个人项目和 POC

- **生产环境**
  - Kubernetes 集群部署
  - Redis Cluster 高可用
  - 多网关实例负载均衡
  - Prometheus + Grafana 监控

- **企业级场景**
  - 使用 MSE 云原生网关（企业版）
  - 多可用区部署
  - 99.99% 高可用保障
  - 专业技术支持

### 26. 性能优化建议
- **缓存优化**
  - 合理设置缓存过期时间
  - 选择合适的相似度阈值
  - 预热高频问题缓存

- **限流配置**
  - 根据业务设置合理的 Token 限额
  - 使用多级限流（全局 + 用户级）
  - 考虑突发流量的缓冲

- **监控告警**
  - 监控缓存命中率
  - 监控 Token 消耗趋势
  - 配置 Quota 预警
  - 监控异常调用模式

### 27. 安全最佳实践
- **API 密钥管理**
  - 定期轮换 API Key
  - 使用环境变量存储密钥
  - 避免硬编码

- **访问控制**
  - 启用认证插件（key-auth/jwt-auth）
  - 配置 IP 白名单
  - 使用 Consumer 隔离

- **数据保护**
  - 启用数据脱敏
  - 配置敏感词过滤
  - 审计日志记录

### 28. 成本优化策略
- **智能缓存**
  - 高频问题缓存命中率 > 80%
  - 成本降低 70%+

- **模型选择**
  - 简单任务用小模型
  - 复杂任务用大模型
  - 基于成本和性能的路由策略

- **Token 控制**
  - 设置 max_tokens 限制
  - 使用 Token 限流
  - 监控和预算管理

## 第九部分：案例分享

### 29. 成功案例
- **通义千问 APP**
  - 支撑百万级用户
  - 毫秒级缓存响应
  - 高可用架构

- **零一万物**
  - 多模型统一管理
  - 成本优化 60%
  - 灵活的配额管理

- **FastGPT**
  - RAG 能力增强
  - 私有知识库集成
  - 开源社区活跃

### 30. 社区和支持
- **开源社区**
  - GitHub: https://github.com/alibaba/higress
  - 文档: https://higress.io
  - 社区论坛
  - 在线 Demo

- **企业支持**
  - MSE 云原生网关（企业版）
  - 99.99% SLA 保障
  - 专业技术支持
  - 功能定制服务

- **学习资源**
  - 官方文档
  - 电子书
  - 视频教程
  - 最佳实践

## 第十部分：总结与展望

### 31. Higress AI 网关价值总结
- **技术价值**
  - 统一 30+ AI 服务商接入
  - 降低 70% 成本
  - 提升 10 倍开发效率
  - 毫秒级缓存响应

- **业务价值**
  - 快速上线 AI 应用
  - 灵活的计费和配额
  - 数据安全合规
  - 降低运维复杂度

- **生态价值**
  - 开源社区活跃
  - 企业版成熟稳定
  - 持续迭代更新
  - 丰富的插件生态

### 32. 未来发展方向
- **更多 AI 能力**
  - 支持更多 LLM 服务商
  - 增强 Agent 编排能力
  - 多模态支持（图像、音频）
  - 更智能的成本优化

- **企业级特性**
  - 更完善的可观测性
  - 更灵活的计费模型
  - 更强大的安全防护
  - 更好的性能优化

- **生态建设**
  - 更丰富的插件市场
  - 更多行业解决方案
  - 更好的社区支持
  - 更完善的文档和教程

### 33. 快速开始
- **5 分钟快速体验**
  1. 安装 Higress
  2. 配置 AI Proxy 插件
  3. 发送第一个 AI 请求
  4. 查看监控和日志

- **推荐学习路径**
  1. 快速开始指南
  2. AI Proxy 基础配置
  3. 缓存和限流配置
  4. 搜索增强和 Agent
  5. 生产环境部署

- **获取帮助**
  - 查阅官方文档
  - 加入社区讨论
  - 提交 Issue
  - 联系技术支持

---

## 附录

### 关键指标对比

| 场景 | 传统方案 | Higress AI 网关 | 提升 |
|------|---------|----------------|------|
| 模型切换成本 | 数周改造 | 几分钟配置 | 降低 95% |
| API 调用延迟 | 2-5s | 100ms（缓存命中） | 提升 20-50 倍 |
| Token 成本 | 基准 100% | 30%（缓存 + 优化） | 降低 70% |
| 开发效率 | 多套 SDK | 统一 OpenAI 接口 | 提升 10 倍 |
| 可观测性 | 分散监控 | 统一 Dashboard | 提升 5 倍 |

### 核心插件速查表

| 插件名称 | 主要功能 | 适用场景 |
|---------|---------|---------|
| ai-proxy | 多模型接入 | 统一 AI 服务 |
| ai-cache | 智能缓存 | 降低成本和延迟 |
| ai-token-ratelimit | Token 限流 | 成本控制 |
| ai-quota | 配额管理 | SaaS 计费 |
| ai-statistics | 监控统计 | 可观测性 |
| ai-data-masking | 数据脱敏 | 隐私保护 |
| ai-search | 搜索增强 | RAG 场景 |
| ai-agent | 工具编排 | 复杂任务 |

### 联系方式

- **GitHub**: https://github.com/alibaba/higress
- **官网**: https://higress.io
- **邮件**: higress@googlegroups.com
- **企业版咨询**: https://www.aliyun.com/product/aliware/mse
